{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akxy4321/miniconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Modification of code to work with Ollama\n",
    "# Import Required Libraries\n",
    "\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.llms import Cohere\n",
    "from llama_index.llms.ollama import Ollama \n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain_chroma import Chroma \n",
    "from llama_parse import LlamaParse\n",
    "from uuid import uuid4\n",
    "import gradio as gr\n",
    "import chromadb\n",
    "import ollama\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "EMBEDDING_MODEL = \"nomic-embed-text\"\n",
    "GENERATION_MODEL = \"llama3.1\"\n",
    "\n",
    "embed_model = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "ollama_ef = embedding_functions.OllamaEmbeddingFunction(\n",
    "    url=\"http://127.0.0.1:11434/api/embeddings\",\n",
    "    model_name=EMBEDDING_MODEL,\n",
    ")\n",
    "llm = Ollama(model=GENERATION_MODEL, request_timeout=5.0)\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=os.path.join('.', 'embeddings'),     \n",
    "                               settings=Settings(allow_reset=True),\n",
    "                               tenant=DEFAULT_TENANT,\n",
    "                               database=DEFAULT_DATABASE,\n",
    "                               )\n",
    "\n",
    "chroma_client.reset()\n",
    "col_name = \"LlamaParse\"\n",
    "col = chroma_client.get_or_create_collection(col_name, embedding_function=ollama_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Custom Parsing Instructions\n",
    "\n",
    "parsing_instructions = '''Answer questions using the information in this pdf and be precise. Avoid Hallucinations, and say you don't know if given data is not enough to answer the question'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded documents\n"
     ]
    }
   ],
   "source": [
    "name = \"Resume\"\n",
    "path = os.path.join('.', 'data', f'{name}.pdf')\n",
    "pickle_path = os.path.join('.', 'data', f'parsed_{name}_documents.pkl')\n",
    "\n",
    "if os.path.exists(pickle_path):\n",
    "    with open(pickle_path, 'rb') as file:\n",
    "        documents= pickle.load(file)\n",
    "        print(\"Loaded documents\")\n",
    "else:\n",
    "    documents = LlamaParse(result_type=\"markdown\", parsing_instructions=parsing_instructions).load_data(path)\n",
    "    with open(pickle_path, 'wb') as pickle_file:\n",
    "        pickle.dump(documents, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "node_parser = MarkdownElementNodeParser(llm=llm, num_workers=8).from_defaults()\n",
    "\n",
    "# Retrieve nodes (text) and objects (table)\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextNode(id_='cc5fc93e-ec7b-41e0-aa13-53c1beaf0760', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cade575f-a988-4dd7-8016-5e0769e74cfa', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='9346a9481d8d224cd8680fcd472bea893812a99f887b1eb2b97f93544bd6d4a8')}, text='Aditya Kushal\\n\\n+91 97664 58874 | adityakushal23@gmail.com | linkedin.com/in/akxy4321 | github.com/AKxy4321\\n\\n Education\\n\\nRV University - CGPA: 9.683/10\\n\\nBengaluru, KA\\n\\nBachelor of Technology in Computer Science, Minor in FinTech\\n\\nNov. 2022 – June 2026\\n\\n Experience\\n\\n Summer Internship\\n\\nJuly 2024 – Present\\n\\nRV University, Bengaluru, KA\\n\\n- Led a team of 3 on pruning deep learning models to reduce its size while retaining accuracy.\\n- Implemented Cosine Similarity to find and prune similar filters to reduce information loss.\\n- Pruned LeNet5 model by 14.5x while having accuracy loss of 0.85.\\n\\n Deep Learning Intern\\n\\nSep. 2023 – Present\\n\\nVectraTech Global, Bengaluru, KA\\n\\n- Trained deep learning models for breast cancer detection.\\n- Trained BIRADS Classification on VGG16 and Breast Cancer Object Detection on Yolov7.\\n\\n Artificial Intelligence Intern\\n\\nAug 2023 – May 2024\\n\\nShaale, Bengaluru, KA\\n\\n- Leveraged OpenAI to build a Chatbot on company’s custom data.\\n- Implemented Cohere’s API to rerank documents and retrieve relevant information.\\n- Implemented Tavily’s API to provide Web Search functionality to the Chatbot.\\n\\n Projects\\n\\n Obstacle Avoidance System for Visually Impaired\\n\\nPython, PyTorch, Ultralytics\\n\\nJan 2024 – May 2024\\n\\n- Trained a Yolov8-nano object detection model to detect potholes, light poles, vehicles, and roadside stalls.\\n- Provides auditory results on number of objects detected along with their categories.\\n\\n Travel Recommendation System\\n\\nPython, Pandas, Scikit-learn\\n\\nJan 2024 – Feb 2024\\n\\n- Built a Travel Recommendation System where you can swipe to accept or reject a category.\\n- Compared to a database and recommended top 10 cities based on the similarities.\\n\\n Technical Skills\\n\\nLanguages: Python, C, Java, SQL, HTML-CSS-JS\\n\\nLibraries: Tensorflow, Pandas, NumPy, Scikit-learn\\n\\nDeveloper Tools: Git, GitHub, Docker, Conda/Pip, VS Code, Intellij', mimetype='text/plain', start_char_idx=1, end_char_idx=1873, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Check output of extraction\n",
    "\n",
    "print(base_nodes)\n",
    "print()\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store embeddings and metadata into chroma\n",
    "\n",
    "for node in base_nodes + objects:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0, separators=[\n",
    "        \"\\n\",\n",
    "        \"\\n\\n\"\n",
    "    ])\n",
    "    split_texts = text_splitter.split_text(node.text)\n",
    "    i = 0\n",
    "    for text in split_texts:\n",
    "        doc = ollama_ef(text)\n",
    "        col.add(documents=text, ids=str(i), embeddings=doc)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return top nodes * split_texts\n",
    "\n",
    "db = Chroma(client=chroma_client, collection_name=col_name, embedding_function=embed_model)\n",
    "retriever = db.as_retriever()\n",
    "query = \"What internships have Aditya completed\"\n",
    "docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='- Leveraged OpenAI to build a Chatbot on company’s custom data.\\n- Implemented Cohere’s API to rerank documents and retrieve relevant information.\\n- Implemented Tavily’s API to provide Web Search functionality to the Chatbot.\\n\\n Projects\\n\\n Obstacle Avoidance System for Visually Impaired\\n\\nPython, PyTorch, Ultralytics\\n\\nJan 2024 – May 2024\\n\\n- Trained a Yolov8-nano object detection model to detect potholes, light poles, vehicles, and roadside stalls.'),\n",
       " Document(page_content='Aditya Kushal\\n\\n+91 97664 58874 | adityakushal23@gmail.com | linkedin.com/in/akxy4321 | github.com/AKxy4321\\n\\n Education\\n\\nRV University - CGPA: 9.683/10\\n\\nBengaluru, KA\\n\\nBachelor of Technology in Computer Science, Minor in FinTech\\n\\nNov. 2022 – June 2026\\n\\n Experience\\n\\n Summer Internship\\n\\nJuly 2024 – Present\\n\\nRV University, Bengaluru, KA\\n\\n- Led a team of 3 on pruning deep learning models to reduce its size while retaining accuracy.'),\n",
       " Document(page_content='- Implemented Cosine Similarity to find and prune similar filters to reduce information loss.\\n- Pruned LeNet5 model by 14.5x while having accuracy loss of 0.85.\\n\\n Deep Learning Intern\\n\\nSep. 2023 – Present\\n\\nVectraTech Global, Bengaluru, KA\\n\\n- Trained deep learning models for breast cancer detection.\\n- Trained BIRADS Classification on VGG16 and Breast Cancer Object Detection on Yolov7.\\n\\n Artificial Intelligence Intern\\n\\nAug 2023 – May 2024\\n\\nShaale, Bengaluru, KA'),\n",
       " Document(page_content='- Provides auditory results on number of objects detected along with their categories.\\n\\n Travel Recommendation System\\n\\nPython, Pandas, Scikit-learn\\n\\nJan 2024 – Feb 2024\\n\\n- Built a Travel Recommendation System where you can swipe to accept or reject a category.\\n- Compared to a database and recommended top 10 cities based on the similarities.\\n\\n Technical Skills\\n\\nLanguages: Python, C, Java, SQL, HTML-CSS-JS\\n\\nLibraries: Tensorflow, Pandas, NumPy, Scikit-learn')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check output of the similarity\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Cohere Reranker\n",
    "\n",
    "compressor = CohereRerank(top_n=10, model=\"rerank-english-v3.0\")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "compressed_docs = compression_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'relevance_score': 0.54664737}, page_content='Aditya Kushal\\n\\n+91 97664 58874 | adityakushal23@gmail.com | linkedin.com/in/akxy4321 | github.com/AKxy4321\\n\\n Education\\n\\nRV University - CGPA: 9.683/10\\n\\nBengaluru, KA\\n\\nBachelor of Technology in Computer Science, Minor in FinTech\\n\\nNov. 2022 – June 2026\\n\\n Experience\\n\\n Summer Internship\\n\\nJuly 2024 – Present\\n\\nRV University, Bengaluru, KA\\n\\n- Led a team of 3 on pruning deep learning models to reduce its size while retaining accuracy.'),\n",
       " Document(metadata={'relevance_score': 0.0006386796}, page_content='- Implemented Cosine Similarity to find and prune similar filters to reduce information loss.\\n- Pruned LeNet5 model by 14.5x while having accuracy loss of 0.85.\\n\\n Deep Learning Intern\\n\\nSep. 2023 – Present\\n\\nVectraTech Global, Bengaluru, KA\\n\\n- Trained deep learning models for breast cancer detection.\\n- Trained BIRADS Classification on VGG16 and Breast Cancer Object Detection on Yolov7.\\n\\n Artificial Intelligence Intern\\n\\nAug 2023 – May 2024\\n\\nShaale, Bengaluru, KA'),\n",
       " Document(metadata={'relevance_score': 6.4522144e-05}, page_content='- Leveraged OpenAI to build a Chatbot on company’s custom data.\\n- Implemented Cohere’s API to rerank documents and retrieve relevant information.\\n- Implemented Tavily’s API to provide Web Search functionality to the Chatbot.\\n\\n Projects\\n\\n Obstacle Avoidance System for Visually Impaired\\n\\nPython, PyTorch, Ultralytics\\n\\nJan 2024 – May 2024\\n\\n- Trained a Yolov8-nano object detection model to detect potholes, light poles, vehicles, and roadside stalls.'),\n",
       " Document(metadata={'relevance_score': 2.195349e-05}, page_content='- Provides auditory results on number of objects detected along with their categories.\\n\\n Travel Recommendation System\\n\\nPython, Pandas, Scikit-learn\\n\\nJan 2024 – Feb 2024\\n\\n- Built a Travel Recommendation System where you can swipe to accept or reject a category.\\n- Compared to a database and recommended top 10 cities based on the similarities.\\n\\n Technical Skills\\n\\nLanguages: Python, C, Java, SQL, HTML-CSS-JS\\n\\nLibraries: Tensorflow, Pandas, NumPy, Scikit-learn')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice how cohere reranker makes the output better\n",
    "\n",
    "compressed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a PDF expert assistant with a focus on accurate and reliable information retrieval from the documents provided to you. \n",
    "You must only answer questions based on the content of these documents. \n",
    "If you do not find the answer in the documents, respond with \"I don't know.\" \n",
    "Avoid providing speculative or unrelated information, and do not pull in knowledge from external sources beyond what is contained in the given documents. \n",
    "Always prioritize correctness and clarity in your responses.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "            <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "            {SYSTEM_PROMPT}<|eot_id|>\n",
    "            <|start_header_id|>user<|end_header_id|>\n",
    "            Query: {query}\n",
    "            Answer: Answer using {compressed_docs}<|eot_id|> \n",
    "            <|start_header_id|>assistant<|end_header_id|>\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided documents, Aditya's internships are:\\n\\n1. Summer Internship at RV University (July 2024 - Present)\\n2. Deep Learning Intern at VectraTech Global (Sep. 2023 - Present)\\n3. Artificial Intelligence Intern at Shaale (Aug 2023 - May 2024)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.generate(prompt=prompt, model=GENERATION_MODEL)['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now we make the chatbot function for gradio\n",
    "# import nest_asyncio\n",
    "\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# def upload_file(files):\n",
    "#     file_paths = [file.name for file in files]\n",
    "#     return file_paths\n",
    "\n",
    "# def chat(query):\n",
    "#     global compression_retriever\n",
    "#     compressed_docs = compression_retriever.invoke(query)\n",
    "#     prompt = f\"\"\"\n",
    "#                <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "#                {SYSTEM_PROMPT}<|eot_id|>\n",
    "#                <|start_header_id|>user<|end_header_id|>\n",
    "#                Query: {query}\n",
    "#                Answer: Answer using {compressed_docs}<|eot_id|> \n",
    "#                <|start_header_id|>assistant<|end_header_id|>\n",
    "#                \"\"\"\n",
    "               \n",
    "#     return ollama.generate(prompt=prompt, model=GENERATION_MODEL)['response']\n",
    "    \n",
    "# chatbot = gr.ChatInterface(fn=chat, title=\"PDFBot\")\n",
    "# chatbot.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
